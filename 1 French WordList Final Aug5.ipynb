{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/alinazhiltsova/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, pos_tag_sents\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('vader_lexicon')\n",
    "import os.path\n",
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from nltk.corpus import wordnet as wn\n",
    "from textblob import TextBlob\n",
    "from afinn import Afinn\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('vader_lexicon')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os. chdir(\"/Users/alinazhiltsova/Desktop/NCI/Thesis/Code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading etymological wordnet for extracting English words with French origin\n",
    "etym = pd.read_csv(\"etymwn.tsv\",sep = '\\t')\n",
    "#etym.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alinazhiltsova/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3781: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n",
      "/Users/alinazhiltsova/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/alinazhiltsova/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#loading etymological wordnet for extracting English words with French origin\n",
    "etym = pd.read_csv(\"etymwn.tsv\",sep = '\\t')\n",
    "#etym.head()\n",
    "\n",
    "#loading English reddit posts written by French speakers\n",
    "french = pd.read_csv(\"reddit_french.csv\")\n",
    "\n",
    "#filtering the EW to get English words\n",
    "is_eng = etym[etym['eng: Penobscot'].str.contains(\"eng:\")]\n",
    "#is_eng.shape\n",
    "#(991181, 3)\n",
    "\n",
    "#filtering the English words to keep only those that have French origin\n",
    "fr_eng = is_eng[is_eng['aaq: Pawanobskewi'].str.contains(\"fra:\")]\n",
    "#fr_eng.shape\n",
    "#(2904, 3)\n",
    "\n",
    "#renaming the columns for convenience\n",
    "fr_eng.rename({'aaq: Pawanobskewi': 'Origin',\n",
    "                                          'rel:etymological_origin_of': 'Relation', \n",
    "                                          'eng: Penobscot':'Word'}, axis=1, inplace=True)\n",
    "                \n",
    "#filtering the df to keep only 'etymological origin of' type of relationship between the words\n",
    "orig_fr_eng = fr_eng[fr_eng['Relation'].str.contains(\"rel:etymological_origin_of\")]\n",
    "#2633 rows × 3 columns\n",
    "\n",
    "#cleaning the rows to remove the first 5 symbols, because they are the same in every row\n",
    "orig_fr_eng['Word'] = orig_fr_eng['Word'].str[5:]\n",
    "orig_fr_eng['Origin'] = orig_fr_eng['Origin'].str[5:]\n",
    "#a warning comes up, but everything works fine - no action required\n",
    "\n",
    "#keeping only words starting with a lowercase letter\n",
    "#words starting with a capital letter are likely to be names\n",
    "#doing this we also remove suffixes\n",
    "orig_fr_eng = orig_fr_eng[orig_fr_eng.Origin.apply(lambda x: x[0].islower())]\n",
    "#orig_fr_eng\n",
    "#2514 rows × 3 columns\n",
    "\n",
    "french.loc[:,'post']= french.post.apply(lambda x : str.lower(x))\n",
    "french.loc[:,'post'] = french.post.apply(lambda x : \" \".join(re.findall('[\\w]+',x)))\n",
    "#https://stackoverflow.com/questions/47947438/preprocessing-string-data-in-pandas-dataframe\n",
    "\n",
    "wordListFr = orig_fr_eng[\"Word\"].tolist()\n",
    "wordSetFr = set(wordListFr)\n",
    "\n",
    "french['lst'] = french['post'].tolist()\n",
    "lst = french['lst'].tolist()\n",
    "lst_words = [set(line.split(' ')) for line in lst]\n",
    "\n",
    "\n",
    "lst_matches = [list(wordSetFr.intersection(line_wordset)) for line_wordset in lst_words]  # list comprehension\n",
    "fr = [l for l in list(zip(lst, lst_matches)) if l[1]]\n",
    "\n",
    "mtch = [match[1] for match in fr] \n",
    "#len(mtch)\n",
    "#14136\n",
    "\n",
    "matchlist = sum(mtch, [])\n",
    "#len(matchlist)\n",
    "#60059\n",
    "\n",
    "matchlist_unique = list(set(matchlist))\n",
    "#len(matchlist_unique)\n",
    "#910\n",
    "\n",
    "matchlist_unique.sort()\n",
    "\n",
    "#to check if the word is in the list\n",
    "#matchlist_unique.count('word')\n",
    "\n",
    "n_synsets = []\n",
    "for x in matchlist_unique:\n",
    "    n_synsets.append(wn.synsets((x), pos='n')) \n",
    "    \n",
    "\n",
    "sns = pd.DataFrame(\n",
    "    {'word': matchlist_unique,\n",
    "     'synsets': n_synsets\n",
    "    })\n",
    "\n",
    "sns = sns[sns['synsets'].map(lambda d: len(d)) > 0]        \n",
    "\n",
    "sns1 = (sns.apply(lambda x: x.str[0]))\n",
    "sns['synset1'] = sns1 ['synsets']\n",
    "\n",
    "lemmas = []\n",
    "for x in sns.synset1:\n",
    "    lemmas.append((x).lemma_names())\n",
    "sns['lemmas'] = lemmas    \n",
    "\n",
    "#remove words that do not have synonyms\n",
    "sns = sns[sns['lemmas'].map(lambda d: len(d)) > 1]\n",
    "\n",
    "sns['1st_synonym'] = sns.lemmas.map(lambda x: x[0]) \n",
    "sns['2nd_synonym'] = sns.lemmas.map(lambda x: x[1]) \n",
    "sns['first_distinct_pair'] = (sns['word'] + ' '+ sns['1st_synonym']).where(sns['word'] != sns['1st_synonym'], \n",
    "                                                   sns['word'] + ' ' + sns['2nd_synonym'])\n",
    "\n",
    "nouns = pd.DataFrame(columns=['words','type'])\n",
    "nouns['words']= sns['first_distinct_pair']\n",
    "nouns['type'] = 'object'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = pd.DataFrame(columns=['words','type'])\n",
    "nouns['words']= sns['first_distinct_pair']\n",
    "nouns['type'] = 'object'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440, 2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "french = pd.read_csv(\"reddit_french.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0j0s</td>\n",
       "      <td>AskEurope</td>\n",
       "      <td>Most of my programs on the Atari were in Engli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0j0s</td>\n",
       "      <td>AskEurope</td>\n",
       "      <td>Merci pour la conversion en km !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>The ring of fiiiire , the ring of fiiire !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>Why would he lift heavy steel bars with steel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>I thought we were friends and that the enemies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>I would watch it happily .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>You\\\\ 're talking to a guy that username is \\ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>Given your username , I sincerely and unoffici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>This is pretty much the what one of the main d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>GILF ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>Thank you for being dumb .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>Yes , Rotschild .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>They keep saying thoughout the world \\ '' muh ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>It is . And everyone is talking about Le Pen h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>Well as you can see in this thread , he had a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>No he didn\\\\'t . Last polls were around 36/37 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>\\ '' Cleaner\\ '' ? In what aspect ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>You can just say German rules .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>It\\\\ 's even funnier when you\\\\ 're french and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>Make Apple pay for it ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>Well I think you guys have some things to thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>Wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>Yeah it never ends good .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>If that can make you happy , your beers are th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>Any good and fresh fromage de ch\\u00e8vre.\\\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>A little bit of the same things here in France...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>EU has to be reformed but it has nothing to do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0kZ</td>\n",
       "      <td>europe</td>\n",
       "      <td>Haha yes , we can say that . But Germinal is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89755</th>\n",
       "      <td>zabadap</td>\n",
       "      <td>europe</td>\n",
       "      <td>In Germany the employment rate is lower but th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89756</th>\n",
       "      <td>zabadap</td>\n",
       "      <td>europe</td>\n",
       "      <td>House of Habsburg much nostalgia ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89757</th>\n",
       "      <td>zabadap</td>\n",
       "      <td>europe</td>\n",
       "      <td>&amp; gt ; Every childhood summer ever.\\\\n\\\\nI am ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89758</th>\n",
       "      <td>zabadap</td>\n",
       "      <td>europe</td>\n",
       "      <td>someone to explain the strange periodic peak o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89759</th>\n",
       "      <td>zabadap</td>\n",
       "      <td>europe</td>\n",
       "      <td>&amp; gt ; I don\\\\'t hate muslims . I hate islam\\\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89760</th>\n",
       "      <td>ze_pequeno</td>\n",
       "      <td>europe</td>\n",
       "      <td>Hey , \\\\n\\\\nISIS has also been built by former...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89761</th>\n",
       "      <td>ze_pequeno</td>\n",
       "      <td>europe</td>\n",
       "      <td>Hey r/europe , \\\\n\\\\nThis may sound stupid , b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89762</th>\n",
       "      <td>ze_pequeno</td>\n",
       "      <td>europe</td>\n",
       "      <td>What about all the people ( including in [ tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89763</th>\n",
       "      <td>ze_pequeno</td>\n",
       "      <td>europe</td>\n",
       "      <td>This is not an effort to save the \\ '' taxicab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89764</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>I think he just points out that 3/5 countries ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89765</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>Care to give an example of a power a president...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89766</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>People are here to have a conversation , not t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89767</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>I personaly like it like that .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89768</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>It has been in every French media , every day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89769</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>Who is this guy who tweets ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89770</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>No I was wondering what the lone Maori dude is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89771</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>Precisely . People might get confuses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89772</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>I have seen several posts on the parliament be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89773</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>How are we supposed to trust the polls ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89774</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>In 2015 they [ abolished a law ordering to kil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89775</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>Well , you know what we did to our king ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89776</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>That should not be a problem , like in the Eur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89777</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>That was [ Sebastien Chabal ] ( http : //imgur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89778</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>From which country where these screenshots mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89779</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>In rugby they always tell about the \\ '' Fight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89780</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>She was actually trying for 40 % or above . Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89781</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>I don\\\\'t know if he runs in a \\ '' winnable\\ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89782</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>La Defense is build at the border of Paris its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89783</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>The French champion will be a drunk Gerard Dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89784</th>\n",
       "      <td>zirglob</td>\n",
       "      <td>europe</td>\n",
       "      <td>Trump hates CNN ( fake news ! Sad ! ) , and CN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89785 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             user  subreddit  \\\n",
       "0            0j0s  AskEurope   \n",
       "1            0j0s  AskEurope   \n",
       "2             0kZ     europe   \n",
       "3             0kZ     europe   \n",
       "4             0kZ     europe   \n",
       "5             0kZ     europe   \n",
       "6             0kZ     europe   \n",
       "7             0kZ     europe   \n",
       "8             0kZ     europe   \n",
       "9             0kZ     europe   \n",
       "10            0kZ     europe   \n",
       "11            0kZ     europe   \n",
       "12            0kZ     europe   \n",
       "13            0kZ     europe   \n",
       "14            0kZ     europe   \n",
       "15            0kZ     europe   \n",
       "16            0kZ     europe   \n",
       "17            0kZ     europe   \n",
       "18            0kZ     europe   \n",
       "19            0kZ     europe   \n",
       "20            0kZ     europe   \n",
       "21            0kZ     europe   \n",
       "22            0kZ     europe   \n",
       "23            0kZ     europe   \n",
       "24            0kZ     europe   \n",
       "25            0kZ     europe   \n",
       "26            0kZ     europe   \n",
       "27            0kZ     europe   \n",
       "28            0kZ     europe   \n",
       "29            0kZ     europe   \n",
       "...           ...        ...   \n",
       "89755     zabadap     europe   \n",
       "89756     zabadap     europe   \n",
       "89757     zabadap     europe   \n",
       "89758     zabadap     europe   \n",
       "89759     zabadap     europe   \n",
       "89760  ze_pequeno     europe   \n",
       "89761  ze_pequeno     europe   \n",
       "89762  ze_pequeno     europe   \n",
       "89763  ze_pequeno     europe   \n",
       "89764     zirglob     europe   \n",
       "89765     zirglob     europe   \n",
       "89766     zirglob     europe   \n",
       "89767     zirglob     europe   \n",
       "89768     zirglob     europe   \n",
       "89769     zirglob     europe   \n",
       "89770     zirglob     europe   \n",
       "89771     zirglob     europe   \n",
       "89772     zirglob     europe   \n",
       "89773     zirglob     europe   \n",
       "89774     zirglob     europe   \n",
       "89775     zirglob     europe   \n",
       "89776     zirglob     europe   \n",
       "89777     zirglob     europe   \n",
       "89778     zirglob     europe   \n",
       "89779     zirglob     europe   \n",
       "89780     zirglob     europe   \n",
       "89781     zirglob     europe   \n",
       "89782     zirglob     europe   \n",
       "89783     zirglob     europe   \n",
       "89784     zirglob     europe   \n",
       "\n",
       "                                                    post  \n",
       "0      Most of my programs on the Atari were in Engli...  \n",
       "1                       Merci pour la conversion en km !  \n",
       "2             The ring of fiiiire , the ring of fiiire !  \n",
       "3      Why would he lift heavy steel bars with steel ...  \n",
       "4      I thought we were friends and that the enemies...  \n",
       "5                             I would watch it happily .  \n",
       "6      You\\\\ 're talking to a guy that username is \\ ...  \n",
       "7      Given your username , I sincerely and unoffici...  \n",
       "8      This is pretty much the what one of the main d...  \n",
       "9                                                 GILF ?  \n",
       "10                                                     E  \n",
       "11                            Thank you for being dumb .  \n",
       "12                                                     N  \n",
       "13                                     Yes , Rotschild .  \n",
       "14     They keep saying thoughout the world \\ '' muh ...  \n",
       "15     It is . And everyone is talking about Le Pen h...  \n",
       "16     Well as you can see in this thread , he had a ...  \n",
       "17     No he didn\\\\'t . Last polls were around 36/37 ...  \n",
       "18                   \\ '' Cleaner\\ '' ? In what aspect ?  \n",
       "19                       You can just say German rules .  \n",
       "20     It\\\\ 's even funnier when you\\\\ 're french and...  \n",
       "21                               Make Apple pay for it ?  \n",
       "22     Well I think you guys have some things to thin...  \n",
       "23                                                   Wow  \n",
       "24                             Yeah it never ends good .  \n",
       "25     If that can make you happy , your beers are th...  \n",
       "26     Any good and fresh fromage de ch\\u00e8vre.\\\\n\\...  \n",
       "27     A little bit of the same things here in France...  \n",
       "28     EU has to be reformed but it has nothing to do...  \n",
       "29     Haha yes , we can say that . But Germinal is a...  \n",
       "...                                                  ...  \n",
       "89755  In Germany the employment rate is lower but th...  \n",
       "89756                 House of Habsburg much nostalgia ?  \n",
       "89757  & gt ; Every childhood summer ever.\\\\n\\\\nI am ...  \n",
       "89758  someone to explain the strange periodic peak o...  \n",
       "89759  & gt ; I don\\\\'t hate muslims . I hate islam\\\\...  \n",
       "89760  Hey , \\\\n\\\\nISIS has also been built by former...  \n",
       "89761  Hey r/europe , \\\\n\\\\nThis may sound stupid , b...  \n",
       "89762  What about all the people ( including in [ tha...  \n",
       "89763  This is not an effort to save the \\ '' taxicab...  \n",
       "89764  I think he just points out that 3/5 countries ...  \n",
       "89765  Care to give an example of a power a president...  \n",
       "89766  People are here to have a conversation , not t...  \n",
       "89767                    I personaly like it like that .  \n",
       "89768  It has been in every French media , every day ...  \n",
       "89769                       Who is this guy who tweets ?  \n",
       "89770  No I was wondering what the lone Maori dude is...  \n",
       "89771              Precisely . People might get confuses  \n",
       "89772  I have seen several posts on the parliament be...  \n",
       "89773           How are we supposed to trust the polls ?  \n",
       "89774  In 2015 they [ abolished a law ordering to kil...  \n",
       "89775        Well , you know what we did to our king ...  \n",
       "89776  That should not be a problem , like in the Eur...  \n",
       "89777  That was [ Sebastien Chabal ] ( http : //imgur...  \n",
       "89778  From which country where these screenshots mad...  \n",
       "89779  In rugby they always tell about the \\ '' Fight...  \n",
       "89780  She was actually trying for 40 % or above . Th...  \n",
       "89781  I don\\\\'t know if he runs in a \\ '' winnable\\ ...  \n",
       "89782  La Defense is build at the border of Paris its...  \n",
       "89783  The French champion will be a drunk Gerard Dep...  \n",
       "89784  Trump hates CNN ( fake news ! Sad ! ) , and CN...  \n",
       "\n",
       "[89785 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>soporific hypnotic</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  words type\n",
       "824  soporific hypnotic  NaN"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns[nouns.isin(['soporific hypnotic'])].dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = nouns[nouns.words != 'adept ace']\n",
    "nouns = nouns[nouns.words != 'aeronautics astronautics']\n",
    "nouns = nouns[nouns.words != 'venal corruptible']\n",
    "nouns = nouns[nouns.words != 'equitable just']\n",
    "nouns = nouns[nouns.words != 'valley vale']\n",
    "nouns = nouns[nouns.words != 'anatomy general_anatomy']\n",
    "nouns = nouns[nouns.words != 'annuity rente']\n",
    "nouns = nouns[nouns.words != 'annex annexe']\n",
    "nouns = nouns[nouns.words != 'annelid annelid_worm']\n",
    "nouns = nouns[nouns.words != 'antibiotic antibiotic_drug']\n",
    "nouns = nouns[nouns.words != 'anomie anomy']\n",
    "nouns = nouns[nouns.words != 'apanage appanage']\n",
    "nouns = nouns[nouns.words != 'appanage apanage']\n",
    "nouns = nouns[nouns.words != 'apologetic excusatory']\n",
    "nouns = nouns[nouns.words != 'apprise advise']\n",
    "nouns = nouns[nouns.words != 'admire look_up_to']\n",
    "nouns = nouns[nouns.words != 'babiroussa babirusa']\n",
    "nouns = nouns[nouns.words != 'barcarolle barcarole']\n",
    "nouns = nouns[nouns.words != 'are ar']\n",
    "nouns = nouns[nouns.words != 'automatize automatise']\n",
    "nouns = nouns[nouns.words != 'arctic Arctic']\n",
    "nouns = nouns[nouns.words != 'aye-aye Daubentonia_madagascariensis']\n",
    "nouns = nouns[nouns.words != 'aerobic aerophilic']\n",
    "nouns = nouns[nouns.words != 'banal commonplace']\n",
    "nouns = nouns[nouns.words != 'bandelet annulet']\n",
    "nouns = nouns[nouns.words != 'bimetallic bimetallistic']\n",
    "nouns = nouns[nouns.words != 'bonduc Kentucky_coffee_tree']\n",
    "nouns = nouns[nouns.words != 'aioli aioli_sauce']\n",
    "nouns = nouns[nouns.words != 'basketball basketball_game']\n",
    "nouns = nouns[nouns.words != 'tuff tufa']\n",
    "nouns = nouns[nouns.words != 'tuner piano_tuner']\n",
    "nouns = nouns[nouns.words != 'tutu Tutu']\n",
    "nouns = nouns[nouns.words != 'telecommunication telecom']\n",
    "nouns = nouns[nouns.words != 'unique alone']\n",
    "nouns = nouns[nouns.words != 'equip fit']\n",
    "nouns = nouns[nouns.words != 'caffeine caffein']\n",
    "nouns = nouns[nouns.words != 'brilliant superb']\n",
    "nouns = nouns[nouns.words != 'carrousel carousel']\n",
    "nouns = nouns[nouns.words != 'capricious freakish']\n",
    "nouns = nouns[nouns.words != 'chanterelle chantarelle']\n",
    "nouns = nouns[nouns.words != 'subpoena subpoena_ad_testificandum']\n",
    "nouns = nouns[nouns.words != 'svelte polished']\n",
    "nouns = nouns[nouns.words != 'symptomatic diagnostic']\n",
    "nouns = nouns[nouns.words != 'syndicate crime_syndicat']\n",
    "nouns = nouns[nouns.words != 'tableau tableau_vivant']\n",
    "nouns = nouns[nouns.words != 'tarot tarot_card']\n",
    "nouns = nouns[nouns.words != 'serval Felis_serval']\n",
    "nouns = nouns[nouns.words != 'sirup syrup']\n",
    "nouns = nouns[nouns.words != 'slang slang_expression']\n",
    "nouns = nouns[nouns.words != 'somatic bodily']\n",
    "nouns = nouns[nouns.words != 'sourdine sordino']\n",
    "nouns = nouns[nouns.words != 'spencer Spencer']\n",
    "nouns = nouns[nouns.words != 'sponsoring sponsor']\n",
    "nouns = nouns[nouns.words != 'renaissance Renaissance']\n",
    "nouns = nouns[nouns.words != 'repent atone']\n",
    "nouns = nouns[nouns.words != 'revivify animate']\n",
    "nouns = nouns[nouns.words != 'riant laughing']\n",
    "nouns = nouns[nouns.words != 'risible amusing']\n",
    "nouns = nouns[nouns.words != 'ricochet carom']\n",
    "nouns = nouns[nouns.words != 'rose rosebush']\n",
    "nouns = nouns[nouns.words != 'reactionary ultraconservative']\n",
    "nouns = nouns[nouns.words != 'rebarbative repellent']\n",
    "nouns = nouns[nouns.words != 'identify place']\n",
    "nouns = nouns[nouns.words != 'idealise idealize']\n",
    "nouns = nouns[nouns.words != 'ignore disregard']\n",
    "nouns = nouns[nouns.words != 'implore beg']\n",
    "nouns = nouns[nouns.words != 'impute ascribe']\n",
    "nouns = nouns[nouns.words != 'inaugural inaugural_address']\n",
    "nouns = nouns[nouns.words != 'inaugurate kick_off']\n",
    "nouns = nouns[nouns.words != 'inept awkward']\n",
    "nouns = nouns[nouns.words != 'inestimable incomputable']\n",
    "nouns = nouns[nouns.words != 'insouciant casual']\n",
    "nouns = nouns[nouns.words != 'jovial gay']\n",
    "nouns = nouns[nouns.words != 'kilogram kg']\n",
    "nouns = nouns[nouns.words != 'kilometre kilometer']\n",
    "nouns = nouns[nouns.words != 'la lanthanum']\n",
    "nouns = nouns[nouns.words != 'lateen lateen_sail']\n",
    "nouns = nouns[nouns.words != 'galvanic voltaic']\n",
    "nouns = nouns[nouns.words != 'gauche graceless']\n",
    "nouns = nouns[nouns.words != 'genteel civilized']\n",
    "nouns = nouns[nouns.words != 'gerbil gerbille']\n",
    "nouns = nouns[nouns.words != 'gerbille gerbil']\n",
    "nouns = nouns[nouns.words != 'girandole girandola']\n",
    "nouns = nouns[nouns.words != 'gelatin gelatine']\n",
    "nouns = nouns[nouns.words != 'gratify satisfy']\n",
    "nouns = nouns[nouns.words != 'hydrogen H']\n",
    "nouns = nouns[nouns.words != 'hypnagogic soporific']\n",
    "nouns = nouns[nouns.words != 'exhale expire']\n",
    "nouns = nouns[nouns.words != 'facetious bantering']\n",
    "nouns = nouns[nouns.words != 'falsify distort']\n",
    "nouns = nouns[nouns.words != 'faux fake']\n",
    "nouns = nouns[nouns.words != 'fils Yemeni_fils']\n",
    "nouns = nouns[nouns.words != 'flamboyant royal_poinciana']\n",
    "nouns = nouns[nouns.words != 'francium Fr']\n",
    "nouns = nouns[nouns.words != 'agronomy scientific_agriculture']\n",
    "nouns = nouns[nouns.words != 'apt disposed']\n",
    "nouns = nouns[nouns.words != 'ariette arietta']\n",
    "nouns = nouns[nouns.words != 'arachnid arachnoid']\n",
    "nouns = nouns[nouns.words != 'aristocratic aristocratical']\n",
    "nouns = nouns[nouns.words != 'arbitral arbitrational']\n",
    "nouns = nouns[nouns.words != 'assist aid']\n",
    "nouns = nouns[nouns.words != 'automatic automatic_rifle']\n",
    "nouns = nouns[nouns.words != 'aver allege']\n",
    "nouns = nouns[nouns.words != 'bandeau brassiere']\n",
    "nouns = nouns[nouns.words != 'beatify exhilarate']\n",
    "nouns = nouns[nouns.words != 'bizarre eccentric']\n",
    "nouns = nouns[nouns.words != 'bourn bourne']\n",
    "nouns = nouns[nouns.words != 'budge Budge']\n",
    "nouns = nouns[nouns.words != 'boule boulle']\n",
    "nouns = nouns[nouns.words != 'briquet briquette']\n",
    "nouns = nouns[nouns.words != 'bromine Br']\n",
    "nouns = nouns[nouns.words != 'brumous foggy']\n",
    "nouns = nouns[nouns.words != 'burnoose burnous']\n",
    "nouns = nouns[nouns.words != 'bye pass']\n",
    "nouns = nouns[nouns.words != 'cadaveric cadaverous']\n",
    "nouns = nouns[nouns.words != 'cajole wheedle']\n",
    "nouns = nouns[nouns.words != 'cam Cam']\n",
    "nouns = nouns[nouns.words != 'carrack carack']\n",
    "nouns = nouns[nouns.words != 'carton cartonful']\n",
    "nouns = nouns[nouns.words != 'center centre']\n",
    "nouns = nouns[nouns.words != 'chabazite chabasite']\n",
    "nouns = nouns[nouns.words != 'champagne bubbly']\n",
    "nouns = nouns[nouns.words != 'charivari shivaree']\n",
    "nouns = nouns[nouns.words != 'shivaree chivaree']\n",
    "nouns = nouns[nouns.words != 'cigarette cigaret']\n",
    "nouns = nouns[nouns.words != 'cite citation']\n",
    "nouns = nouns[nouns.words != 'clarify clear_up']\n",
    "nouns = nouns[nouns.words != 'classify class']\n",
    "nouns = nouns[nouns.words != 'coy demure']\n",
    "nouns = nouns[nouns.words != 'colossal prodigious']\n",
    "nouns = nouns[nouns.words != 'comestible edible']\n",
    "nouns = nouns[nouns.words != 'complex composite']\n",
    "nouns = nouns[nouns.words != 'concord Concord']\n",
    "nouns = nouns[nouns.words != 'compute calculate']\n",
    "nouns = nouns[nouns.words != 'complaisant obliging']\n",
    "nouns = nouns[nouns.words != 'coquette flirt']\n",
    "nouns = nouns[nouns.words != 'console console_table']\n",
    "nouns = nouns[nouns.words != 'consult confer_with']\n",
    "nouns = nouns[nouns.words != 'country-dance country_dancing']\n",
    "nouns = nouns[nouns.words != 'coriander coriander_plant']\n",
    "nouns = nouns[nouns.words != 'corps army_corps']\n",
    "nouns = nouns[nouns.words != 'corselet corslet']\n",
    "nouns = nouns[nouns.words != 'coincide co-occur']\n",
    "nouns = nouns[nouns.words != 'crochet crocheting']\n",
    "nouns = nouns[nouns.words != 'cerebral intellectual']\n",
    "nouns = nouns[nouns.words != 'ceterach Ceterach']\n",
    "nouns = nouns[nouns.words != 'deluxe gilded']\n",
    "nouns = nouns[nouns.words != 'demitasse cafe_noir']\n",
    "nouns = nouns[nouns.words != 'despoil plunder']\n",
    "nouns = nouns[nouns.words != 'dessert sweet']\n",
    "nouns = nouns[nouns.words != 'digitigrade digitigrade_mammal']\n",
    "nouns = nouns[nouns.words != 'diopter dioptre']\n",
    "nouns = nouns[nouns.words != 'disconcert confuse']\n",
    "nouns = nouns[nouns.words != 'distrait distracted']\n",
    "nouns = nouns[nouns.words != 'domino Domino']\n",
    "nouns = nouns[nouns.words != 'dormition Dormition']\n",
    "nouns = nouns[nouns.words != 'dot point']\n",
    "nouns = nouns[nouns.words != 'dugong Dugong_dugon']\n",
    "nouns = nouns[nouns.words != 'debark disembark']\n",
    "nouns = nouns[nouns.words != 'dogmatic dogmatical']\n",
    "nouns = nouns[nouns.words != 'dog domestic_dog']\n",
    "nouns = nouns[nouns.words != 'decapitate behead']\n",
    "nouns = nouns[nouns.words != 'decollete low-cut']\n",
    "nouns = nouns[nouns.words != 'delimit specify']\n",
    "nouns = nouns[nouns.words != 'defiant noncompliant']\n",
    "nouns = nouns[nouns.words != 'democratize democratise']\n",
    "nouns = nouns[nouns.words != 'depute delegate']\n",
    "nouns = nouns[nouns.words != 'derange unbalance']\n",
    "nouns = nouns[nouns.words != 'disastrous black']\n",
    "nouns = nouns[nouns.words != 'deshabille dishabille']\n",
    "nouns = nouns[nouns.words != 'disorganize disorganise']\n",
    "nouns = nouns[nouns.words != 'ellipse oval']\n",
    "nouns = nouns[nouns.words != 'embarrass abash']\n",
    "nouns = nouns[nouns.words != 'enjambment enjambement']\n",
    "nouns = nouns[nouns.words != 'inter bury']\n",
    "nouns = nouns[nouns.words != 'entourage cortege']\n",
    "nouns = nouns[nouns.words != 'vie compete']\n",
    "nouns = nouns[nouns.words != 'escargots escargot']\n",
    "nouns = nouns[nouns.words != 'evince express']\n",
    "nouns = nouns[nouns.words != 'fibre fiber']\n",
    "nouns = nouns[nouns.words != 'fiber fibre']\n",
    "nouns = nouns[nouns.words != 'file data_file']\n",
    "nouns = nouns[nouns.words != 'focus focusing']\n",
    "nouns = nouns[nouns.words != 'fusee fusee_drive']\n",
    "nouns = nouns[nouns.words != 'febrifuge antipyretic']\n",
    "nouns = nouns[nouns.words != 'federal Federal']\n",
    "nouns = nouns[nouns.words != 'gaffe faux_pas']\n",
    "nouns = nouns[nouns.words != 'gibbon Gibbon']\n",
    "nouns = nouns[nouns.words != 'gauze gauze_bandage']\n",
    "nouns = nouns[nouns.words != 'gelatine gelatin']\n",
    "nouns = nouns[nouns.words != 'ha-ha hee-haw']\n",
    "nouns = nouns[nouns.words != 'hautbois oboe']\n",
    "nouns = nouns[nouns.words != 'hypnotic soporific']\n",
    "nouns = nouns[nouns.words != 'idolater idolizer']\n",
    "nouns = nouns[nouns.words != 'gelatine gelatin']\n",
    "nouns = nouns[nouns.words != 'hockey field_hockey']\n",
    "nouns = nouns[nouns.words != 'hyoid hyoid_bone']\n",
    "nouns = nouns[nouns.words != 'iodine iodin']\n",
    "nouns = nouns[nouns.words != 'irascible choleric']\n",
    "nouns = nouns[nouns.words != 'jet jet_plane']\n",
    "nouns = nouns[nouns.words != 'largess largesse']\n",
    "nouns = nouns[nouns.words != 'lazaret lazaretto']\n",
    "nouns = nouns[nouns.words != 'le lupus_erythematosus']\n",
    "nouns = nouns[nouns.words != 'loir Glis_glis']\n",
    "nouns = nouns[nouns.words != 'louche shady']\n",
    "nouns = nouns[nouns.words != 'lucrative moneymaking']\n",
    "nouns = nouns[nouns.words != 'legume leguminous_plant']\n",
    "nouns = nouns[nouns.words != 'macabre ghastly']\n",
    "nouns = nouns[nouns.words != 'maisonette maisonnette']\n",
    "nouns = nouns[nouns.words != 'mandarin mandarin_orange']\n",
    "nouns = nouns[nouns.words != 'manganese Mn']\n",
    "nouns = nouns[nouns.words != 'maquis Maquis']\n",
    "nouns = nouns[nouns.words != 'match lucifer'] #archaic meaning of lucifer\n",
    "nouns = nouns[nouns.words != 'milkshake milk_shake']\n",
    "nouns = nouns[nouns.words != 'milligram mg']\n",
    "nouns = nouns[nouns.words != 'mollusc mollusk']\n",
    "nouns = nouns[nouns.words != 'morgue mortuary']\n",
    "nouns = nouns[nouns.words != 'mot bon_mot']\n",
    "nouns = nouns[nouns.words != 'mouflon moufflon']\n",
    "nouns = nouns[nouns.words != 'en nut']\n",
    "nouns = nouns[nouns.words != 'muscat muskat']\n",
    "nouns = nouns[nouns.words != 'mystify perplex']\n",
    "nouns = nouns[nouns.words != 'meter metre']\n",
    "nouns = nouns[nouns.words != 'metre meter']\n",
    "nouns = nouns[nouns.words != 'metacenter metacentre']\n",
    "nouns = nouns[nouns.words != 'metacentre metacenter']\n",
    "nouns = nouns[nouns.words != 'naive naif']\n",
    "nouns = nouns[nouns.words != 'nitre potassium_nitrate']\n",
    "nouns = nouns[nouns.words != 'nitrogen N']\n",
    "nouns = nouns[nouns.words != 'nocturne notturno']\n",
    "nouns = nouns[nouns.words != 'offensive offense']\n",
    "nouns = nouns[nouns.words != 'oleaginous buttery']\n",
    "nouns = nouns[nouns.words != 'orientalism Orientalism']\n",
    "nouns = nouns[nouns.words != 'oriole Old_World_oriole']\n",
    "nouns = nouns[nouns.words != 'orthopedic orthopaedic']\n",
    "nouns = nouns[nouns.words != 'oxygen O']\n",
    "nouns = nouns[nouns.words != 'palmier booming']\n",
    "nouns = nouns[nouns.words != 'panda giant_panda']\n",
    "nouns = nouns[nouns.words != 'parity para']\n",
    "nouns = nouns[nouns.words != 'passive passive_voice']\n",
    "nouns = nouns[nouns.words != 'persecute oppress']\n",
    "nouns = nouns[nouns.words != 'pickpocket cutpurse']\n",
    "nouns = nouns[nouns.words != 'piolet ice_ax']\n",
    "nouns = nouns[nouns.words != 'pipette pipet']\n",
    "nouns = nouns[nouns.words != 'pipistrelle pipistrel']\n",
    "nouns = nouns[nouns.words != 'piston Piston']\n",
    "nouns = nouns[nouns.words != 'plaintive mournful']\n",
    "nouns = nouns[nouns.words != 'plutonic irruptive']\n",
    "nouns = nouns[nouns.words != 'polemic polemicist']\n",
    "nouns = nouns[nouns.words != 'po polonium']\n",
    "nouns = nouns[nouns.words != 'pragmatic pragmatic_sanction']\n",
    "nouns = nouns[nouns.words != 'practicable operable']\n",
    "nouns = nouns[nouns.words != 'prodigious colossal']\n",
    "nouns = nouns[nouns.words != 'prompt prompting']\n",
    "nouns = nouns[nouns.words != 'prosaic matter-of-fact']\n",
    "nouns = nouns[nouns.words != 'prude puritan']\n",
    "nouns = nouns[nouns.words != 'prehistoric prehistorical']\n",
    "nouns = nouns[nouns.words != 'ptomaine ptomain']\n",
    "nouns = nouns[nouns.words != 'pinnace tender']\n",
    "nouns = nouns[nouns.words != 'periodic periodical']\n",
    "nouns = nouns[nouns.words != 'reconnoiter scout']\n",
    "nouns = nouns[nouns.words != 'reconnoitre scout']\n",
    "nouns = nouns[nouns.words != 'redoubtable formidable']\n",
    "nouns = nouns[nouns.words != 'remarkable singular']\n",
    "nouns = nouns[nouns.words != 'regorge vomit']\n",
    "nouns = nouns[nouns.words != 'remake remaking']\n",
    "nouns = nouns[nouns.words != 'rally mass_meeting']\n",
    "nouns = nouns[nouns.words != 'radical group']\n",
    "nouns = nouns[nouns.words != 'ramify complexify']\n",
    "nouns = nouns[nouns.words != 'risque blue']\n",
    "nouns = nouns[nouns.words != 'ruttier rutted']\n",
    "nouns = nouns[nouns.words != 'rail railing']\n",
    "nouns = nouns[nouns.words != 'reprimand rebuke']\n",
    "nouns = nouns[nouns.words != 'resistant immune']\n",
    "nouns = nouns[nouns.words != 'reveal uncover']\n",
    "nouns = nouns[nouns.words != 'soar zoom']\n",
    "nouns = nouns[nouns.words != 'sabre saber']\n",
    "nouns = nouns[nouns.words != 'sainfoin sanfoin']\n",
    "nouns = nouns[nouns.words != 'savant initiate']\n",
    "nouns = nouns[nouns.words != 'settee settle']\n",
    "nouns = nouns[nouns.words != 'somber drab']\n",
    "nouns = nouns[nouns.words != 'sumptuous deluxe']\n",
    "nouns = nouns[nouns.words != 'soporific hypnotic']\n",
    "nouns = nouns[nouns.words != 'sprint dash']\n",
    "nouns = nouns[nouns.words != 'stagnant dead']\n",
    "nouns = nouns[nouns.words != 'tactile haptic']\n",
    "nouns = nouns[nouns.words != 'talus scree']\n",
    "nouns = nouns[nouns.words != 'tentative probationary']\n",
    "nouns = nouns[nouns.words != 'theatre theater']\n",
    "nouns = nouns[nouns.words != 'timid cautious']\n",
    "nouns = nouns[nouns.words != 'titer titre']\n",
    "nouns = nouns[nouns.words != 'titre titer']\n",
    "nouns = nouns[nouns.words != 'ton short_ton']\n",
    "nouns = nouns[nouns.words != 'eclectic eclecticist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns['words'] = nouns.words.replace(' ', ', ', regex=True)\n",
    "nouns['words'] = nouns.words.replace('_', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = nouns[nouns.words != 'eject, chuck_out']\n",
    "nouns = nouns[nouns.words != 'alert, qui vive']\n",
    "nouns = nouns[nouns.words != 'attitude, mental attitude']\n",
    "nouns = nouns[nouns.words != 'bail, bail bond']\n",
    "nouns = nouns[nouns.words != 'billion, one million million']\n",
    "nouns = nouns[nouns.words != 'calque, calque formation']\n",
    "nouns = nouns[nouns.words != 'campaign, political campaign']\n",
    "nouns = nouns[nouns.words != 'capitalism, capitalist economy']\n",
    "nouns = nouns[nouns.words != 'cereal, cereal grass']\n",
    "nouns = nouns[nouns.words != 'clementine, clementine tree']\n",
    "nouns = nouns[nouns.words != 'crepe, crepe paper']\n",
    "nouns = nouns[nouns.words != 'croissant, crescent roll']\n",
    "nouns = nouns[nouns.words != 'deputy, deputy sheriff']\n",
    "nouns = nouns[nouns.words != 'douche, douche bag']\n",
    "nouns = nouns[nouns.words != 'fester, suppurating sore']\n",
    "nouns = nouns[nouns.words != 'guillotine, closure by compartment']\n",
    "nouns = nouns[nouns.words != 'ideology, political orientation']\n",
    "nouns = nouns[nouns.words != 'journalism, news media']\n",
    "nouns = nouns[nouns.words != 'masquerade, masquerade party']\n",
    "nouns = nouns[nouns.words != 'menu, bill of fare']\n",
    "nouns = nouns[nouns.words != 'metric, metric function']\n",
    "nouns = nouns[nouns.words != 'pedal, pedal point']\n",
    "nouns = nouns[nouns.words != 'positivism, logical positivism']\n",
    "nouns = nouns[nouns.words != 'prime, prime quantity']\n",
    "nouns = nouns[nouns.words != 'proprietary, proprietorship']\n",
    "nouns = nouns[nouns.words != 'psychology, psychological science']\n",
    "nouns = nouns[nouns.words != 'reconnaissance, reconnaissance mission']\n",
    "nouns = nouns[nouns.words != 'routine, modus operandi']\n",
    "nouns = nouns[nouns.words != 'sally, wisecrack']\n",
    "nouns = nouns[nouns.words != 'sortie, sally']\n",
    "nouns = nouns[nouns.words != 'terminal, terminus']\n",
    "nouns = nouns[nouns.words != 'tourniquet, compression bandage']\n",
    "nouns = nouns[nouns.words != 'vise, bench vise']\n",
    "nouns = nouns[nouns.words != 'tone, tone of voice']\n",
    "nouns = nouns[nouns.words != 'syndicate, crime syndicate']\n",
    "nouns = nouns[nouns.words != 'tangerine, tangerine tree']\n",
    "nouns = nouns[nouns.words != 'parameter, parametric quantity']\n",
    "nouns = nouns[nouns.words != 'ounce, troy ounce']\n",
    "nouns = nouns[nouns.words != 'pretext, stalking-horse']\n",
    "nouns = nouns[nouns.words != 'lingerie, intimate apparel']\n",
    "nouns = nouns[nouns.words != 'positivism, logical positivism']\n",
    "nouns = nouns[nouns.words != 'ballet, concert dance']\n",
    "nouns = nouns[nouns.words != 'chamois, chamois leather']\n",
    "nouns = nouns[nouns.words != 'celery, cultivated celery']\n",
    "nouns = nouns[nouns.words != 'clique, coterie']\n",
    "nouns = nouns[nouns.words != 'compote, fruit compote']\n",
    "nouns = nouns[nouns.words != 'contrast, direct contrast']\n",
    "nouns = nouns[nouns.words != 'date, day of the month']\n",
    "nouns = nouns[nouns.words != 'defeat, licking']\n",
    "nouns = nouns[nouns.words != 'diplomacy, diplomatic negotiations']\n",
    "nouns = nouns[nouns.words != 'promotion, publicity']\n",
    "nouns = nouns[nouns.words != 'publicity, promotion']\n",
    "nouns = nouns[nouns.words != 'crayon, wax crayon']\n",
    "nouns = nouns[nouns.words != 'expertise, expertness']\n",
    "nouns = nouns[nouns.words != 'hospitality, cordial reception']\n",
    "nouns = nouns[nouns.words != 'hut, army hut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns.shape\n",
    "#292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns.to_csv(\"nouns_fr_final.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
